# -*- coding: utf-8 -*-
"""T1_T2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1APVxlkoHbdbeoqFZFKatgDs31emSIpNB

# CONVERTING T1 MRI IMAGES TO T2 AND VICE VERSA
* In this notebook we will convert the T1 type of MRI image to T2
* As the next step T2 MRI images will be converted to T1 type.

## Pipeline of the project
1. Importing Libraries
2. Data Loading and Visualization
3. Data Preprocessing
4. Model Building
5. Model Training
6. Generating a GIF

### 1. Importing Libraries
"""

## importing important libraries
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from skimage.transform import resize
import imageio
import glob
import os
from PIL import Image

"""### 2. Data Loading and Visualisation

#### Mouting Google drive on Google Colab
"""

# Mounting google drive on colab
from google.colab import drive
drive.mount("/content/gdrive")

"""#### Data Loading"""

# Copying data from gdrive to present working directory
!cp -r "/content/gdrive/MyDrive/GAN/MRI+T1_T2+Dataset" "./"

## Define the directories containing the T1 and T2 images
t1_dir ="/content/MRI+T1_T2+Dataset/Tr1/TrainT1"
t2_dir = "/content/MRI+T1_T2+Dataset/Tr2/TrainT2"

# Get a list of all image file paths in the directory
tr1_images = [os.path.join(t1_dir,file) for file in os.listdir(t1_dir) if file.endswith("png")]
tr2_images = [os.path.join(t2_dir,file) for file in os.listdir(t2_dir) if file.endswith("png")]

# Initialize an empty list to store the images
images_t1 = []
images_t2 = []

# Loop through each image file, open it, and append its array to the images list
for image_file in tr1_images:
  with Image.open(image_file) as img:
    img_array = np.array(img)
    images_t1.append(img_array)


# Similarly appending the T2 images to another list
for image_file in tr2_images:
  with Image.open(image_file) as img:
    img_array = np.array(img)
    images_t2.append(img_array)

# Convert the list of images to a single numpy array
t1_images = np.array(images_t1)
t2_images = np.array(images_t2)

# Check the number of images obtained
print(f"There are T1:{t1_images.shape[0]} Images")
print(f"There are T2:{t2_images.shape[0]} Images")

# Check the shape of the resulting array
print(f"T1 shape:{t1_images.shape}")
print(f"T2 shape:{t2_images.shape}")

"""#### Declare Batch size"""

BATCH_SIZE=10

"""#### Visualizing both T1 and T2 image"""

# Visualizing T1 image
plt.figure(figsize=(4,4))
plt.imshow(t1_images[0],cmap="gray")
plt.title("T1 Image")
plt.show()

## Visualizing T2 image
plt.figure(figsize=(4,4))
plt.imshow(t2_images[0],cmap="gray")
plt.title("T2 Image")
plt.show()

"""### 3. Data Preprocessing
*   Data Resizing
*   Data Reshaping
*   Batch and Shuffle Data

#### Resize images to (256,256)
"""

# Resizing for T1 images
img_t1_data = np.zeros((t1_images.shape[0],256,256))
for index,img in enumerate(t1_images):
  img_t1_data[index,:,:] = resize(image=img,output_shape=(256,256))
print(f"T1 new shape:{img_t1_data.shape}")

# Resizing for T2 images
img_t2_data = np.zeros((t2_images.shape[0],256,256))
for index,img in enumerate(t2_images):
  img_t2_data[index,:,:] = resize(image=img,output_shape=(256,256))
print(f"T2 new shape:{img_t2_data.shape}")

"""#### Reshape Images to (256,256,1) with float pixel values"""

img_t1_data = img_t1_data.reshape(img_t1_data.shape[0],256,256,1).astype("float32")
img_t2_data = img_t2_data.reshape(img_t2_data.shape[0],256,256,1).astype("float32")

"""#### Batch and shuffle the data(Creating a generator object)"""

img_t1_data = tf.data.Dataset.from_tensor_slices(img_t1_data).shuffle(img_t1_data.shape[0],seed=42).batch(BATCH_SIZE)
img_t2_data = tf.data.Dataset.from_tensor_slices(img_t2_data).shuffle(img_t2_data.shape[0],seed=42).batch(BATCH_SIZE)

## Visualising a sample image from 1st batch
# T1 image
sample_t1 = next(iter(img_t1_data))
plt.figure(figsize=(4,4))
plt.imshow(sample_t1[0].numpy(),cmap="gray")
plt.title("T1 image")
plt.show()

# T2 image
sample_t2 = next(iter(img_t2_data))
plt.figure(figsize=(4,4))
plt.imshow(sample_t2[0].numpy(),cmap="gray")
plt.title("T2 image")
plt.show()

"""### 4. Model Building
* Instance Normalization
* Downsampling, Upsampling and Unet
* Generator Building using Unet
* Discriminator Building

#### Instance Normalisation
"""

class InstanceNormalization(tf.keras.layers.Layer):
    # Initialization of Objects
    def __init__(self, epsilon=1e-5):
        # calling parent's init
        super(InstanceNormalization, self).__init__()
        self.epsilon = epsilon

    def build(self, input_shape):
        self.scale = self.add_weight(
            name='scale',
            shape=input_shape[-1:],
            initializer=tf.random_normal_initializer(1., 0.02),
            trainable=True)
        self.offset = self.add_weight(
            name='offset',
            shape=input_shape[-1:],
            initializer='zeros',
            trainable=True)

    def call(self, x):
        # Compute Mean and Variance, Axes=[1,2] ensures Instance Normalization
        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)
        inv = tf.math.rsqrt(variance + self.epsilon)
        normalized = (x - mean) * inv
        return self.scale * normalized + self.offset

"""#### Downsampling"""

def downsample(filters, size, apply_norm=True):
    initializer = tf.random_normal_initializer(0., 0.02)
    result = tf.keras.Sequential()
    # Add Conv2d layer
    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',
                                      kernel_initializer=initializer, use_bias=False))
    # Add Normalization layer
    if apply_norm:
        result.add(InstanceNormalization())
    # Add Leaky Relu Activation
    result.add(tf.keras.layers.LeakyReLU())
    return result

"""#### Upsampling"""

def upsample(filters, size, apply_dropout=False):
    initializer = tf.random_normal_initializer(0., 0.02)
    result = tf.keras.Sequential()
    # Add Transposed Conv2d layer
    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',
                                               kernel_initializer=initializer, use_bias=False))
    # Add Normalization Layer
    result.add(InstanceNormalization())
    # Conditionally add Dropout layer
    if apply_dropout:
        result.add(tf.keras.layers.Dropout(0.5))
    # Add Relu Activation Layer
    result.add(tf.keras.layers.ReLU())
    return result

"""#### Unet Architecture"""

# Unet Generator is a combination of Convolution + Transposed Convolution Layers
def unet_generator():
    down_stack = [
        downsample(64, 4, False), # (bs, 16, 16, 64)
        downsample(128, 4), # (bs, 8, 8, 128)
        downsample(128, 4), # (bs, 4, 4, 128)
        downsample(128, 4), # (bs, 2, 2, 128)
        downsample(128, 4),
        downsample(128, 4),
        downsample(128, 4),
        downsample(128, 4) # (bs, 1, 1, 128)
    ]
    up_stack = [
        upsample(128, 4, True), # (bs, 2, 2, 256)
        upsample(128, 4, True), # (bs, 4, 4, 256)
        upsample(128, 4), # (bs, 8, 8, 256)
        upsample(128, 4), # (bs, 16, 16, 128)
        upsample(128, 4),
        upsample(128, 4),
        upsample(128, 4),
        upsample(64, 4)
    ]
    initializer = tf.random_normal_initializer(0., 0.02)
    last = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, padding='same', kernel_initializer=initializer,
                                           activation='tanh') # (bs, 32, 32, 1)
    concat = tf.keras.layers.Concatenate()
    inputs = tf.keras.layers.Input(shape=[256, 256, 1])
    x = inputs
    # Downsampling through the model
    skips = []
    for down in down_stack:
        x = down(x)
        skips.append(x)

    skips = reversed(skips[:-1])
    # Upsampling and establishing the skip connections
    for up, skip in zip(up_stack, skips):
        x = up(x)
        x = concat([x, skip])
    x = last(x)
    return tf.keras.Model(inputs=inputs, outputs=x)

"""#### Generator"""

# Initialising both G and F generators
generator_g = unet_generator()
generator_f = unet_generator()

# Generator architecture
generator_g.summary()

"""#### Discriminator"""

# Discriminators only contain Convolutional Layers and no Transposed Convolution is not used
def discriminator():
    initializer = tf.random_normal_initializer(0., 0.02)
    # add input layer of size (32, 32, 1)
    inp = tf.keras.layers.Input(shape=[256, 256, 1], name='input_image')
    x = inp

    # add downsampling step here
    down1 = downsample(64, 4, False)(x) # (bs, 16, 16, 64)
    down2 = downsample(128, 4)(down1) # (bs, 8, 8, 128)
    down3 = downsample(128, 4)(down2)
    down4 = downsample(128, 4)(down3)
    down5 = downsample(128, 4)(down4)
    # add a padding layer here
    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down5) # (bs, 10, 10, 128)

    # implement a concrete downsampling layer here
    conv = tf.keras.layers.Conv2D(256, 4, strides=1, kernel_initializer=initializer,
                                  use_bias=False)(zero_pad1) # (bs, 7, 7, 256)
    norm1 = InstanceNormalization()(conv)
    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)

    # apply zero padding layer
    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 9, 9, 256)

    # add a last pure 2D Convolution layer
    last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 6, 6, 1)
    return tf.keras.Model(inputs=inp, outputs=last)

discriminator_x = discriminator()
discriminator_y = discriminator()

discriminator_x.summary()

"""### 5. Model Training

* Declare Loss type
* Calculate Discriminator Loss
* Calculate Generator Loss
* Cycle Loss
* Identity Loss
* Optimizer
* Checkpoint Initialization
* Training Flow

#### Checking the output of the untrained Generator
"""

to_T2_data = generator_g(sample_t1)
to_T1_data = generator_f(sample_t2)
plt.figure(figsize=(4, 4))

imgs = [sample_t1, to_T2_data, sample_t2, to_T1_data]
title = ['T1_data', 'To T2_data', 'T2_data', 'To T1_data']

for i in range(len(imgs)):
    plt.subplot(2, 2, i+1)
    plt.title(title[i])
    plt.imshow(imgs[i][0].numpy()[:, :, 0], cmap='gray')
    plt.axis('off')
plt.show()

"""#### Declare Loss Type"""

# Loss type would be Binary Cross Entropy
loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)

"""#### Discriminator Loss
It consists of two types of losses
1.    Loss on Real Data
2.    Loss on Fake Data
"""

def discriminator_loss(real, generated):
    real_loss = loss_obj(tf.ones_like(real), real)
    generated_loss = loss_obj(tf.zeros_like(generated), generated)
    total_disc_loss = real_loss + generated_loss
    return total_disc_loss * 0.5 # mean of losses

"""#### Generator Loss"""

def generator_loss(generated):
    return loss_obj(tf.ones_like(generated), generated)

"""#### Cycle Loss"""

def calc_cycle_loss(real_image, cycled_image):
    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))
    return 10.0 * loss1

"""#### Identity Loss"""

def identity_loss(real_image, same_image):
    loss = tf.reduce_mean(tf.abs(real_image - same_image))
    return 0.5*loss

"""#### Optimizer"""

generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

"""#### EPOCHS"""

EPOCHS = 2000

"""#### Checkpoint Initialisation"""

checkpoint_path = "./Trained_Model"

ckpt = tf.train.Checkpoint(generator_g=generator_g,
                           generator_f=generator_f,
                           discriminator_x=discriminator_x,
                           discriminator_y=discriminator_y,
                           generator_g_optimizer=generator_g_optimizer,
                           generator_f_optimizer=generator_f_optimizer,
                           discriminator_x_optimizer=discriminator_x_optimizer,
                           discriminator_y_optimizer=discriminator_y_optimizer)

ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)

# if a checkpoint exists, restore the latest checkpoint.
if ckpt_manager.latest_checkpoint:
    ckpt.restore(ckpt_manager.latest_checkpoint)
    print ('Latest checkpoint restored!!')

#Function to show Images output by Generators while Training
def generate_images(model1, test_input1, model2, test_input2):
    prediction1 = model1(test_input1)
    prediction2 = model2(test_input2)
    plt.figure(figsize=(8, 4))
    display_list = [test_input1[0], prediction1[0], test_input2[0], prediction2[0]]
    title = ['T1_Input_Image', 'Predicted_T2_Image', 'T2_Input_Image', 'Predicted_T1_Image']
    for i in range(4):
        plt.subplot(1, 4, i+1)
        plt.title(title[i])
        plt.imshow(display_list[i].numpy()[:, :, 0], cmap='gray')
        plt.axis('off')

    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()

"""#### Training Flow
Sequence of Training Flow


1.   Generate Fake Y and Cycled X
2.   Generate Fake X and Cycled Y
3.   Generate Fake Images through G and F for Identity Loss.
4.   Calculate Discriminator Loss for Disc X and Disc Y on Fake Data for Generator Training.
5.   Calculate Generator Loss on Discriminator.
6.   Calculate Cycled Loss on Cycled Images from step 1 and 2.
7.   Calculate Total Generator Loss - Disc Loss + Cycled Loss + Identity Loss
8.   Calculate Discriminator Loss on both Fake and Real Images for Disc X and Y for Disc Training.
9.   Calculate the Gradients and update the weight and bias of models.


"""

@tf.function
def train_step(real_x, real_y):
    # persistent is set to True because the tape is used more than
    # once to calculate the gradients.
    with tf.GradientTape(persistent=True) as tape:
        # Generator G translates X -> Y
        # Generator F translates Y -> X
        fake_y = generator_g(real_x, training=True)
        cycled_x = generator_f(fake_y, training=True)

        fake_x = generator_f(real_y, training=True)
        cycled_y = generator_g(fake_x, training=True)

        # same_x and same_y are used for identity loss.
        same_x = generator_f(real_x, training=True)
        same_y = generator_g(real_y, training=True)

        disc_real_x = discriminator_x(real_x, training=True)
        disc_real_y = discriminator_y(real_y, training=True)

        disc_fake_x = discriminator_x(fake_x, training=True)
        disc_fake_y = discriminator_y(fake_y, training=True)

        # calculate the loss
        gen_g_loss = generator_loss(disc_fake_y)
        gen_f_loss = generator_loss(disc_fake_x)

        total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)

        # Total generator loss = BCE loss + cycle loss + identity loss
        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)
        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)

        # Discriminator's loss
        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)
        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)

    # Calculate the gradients for generator and discriminator
    generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)
    generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)

    discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)
    discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)

    # Apply the gradients to the optimizer
    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))
    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))

    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))
    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))

"""#### Train the CycleGAN Model for several Epochs"""

for epoch in range(1, EPOCHS+1):
    for image_x, image_y in tf.data.Dataset.zip((img_t1_data, img_t2_data)):
        train_step(image_x, image_y)
    generate_images(generator_g, sample_t1, generator_f, sample_t2)
    ckpt_save_path = ckpt_manager.save()
    print('Saving checkpoint for epoch', epoch, 'at', ckpt_save_path)

anim_file = 'cyclegan.gif'
with imageio.get_writer(anim_file, mode='I') as writer:
  filenames = glob.glob('image*.png')
  filenames = sorted(filenames)
  for filename in filenames:
    image = imageio.imread(filename)
    writer.append_data(image)
  image = imageio.imread(filename)
  writer.append_data(image)

pip install git+https://github.com/tensorflow/docs

import tensorflow_docs.vis.embed as embed
embed.embed_file(anim_file)